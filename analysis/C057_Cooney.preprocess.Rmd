---
title: "Preprocessing the Cooney (C057) memory CD4+ T-cell data set"
description: |
author:
  - name: Peter Hickey 
    url: https://peterhickey.org
    affiliation: Single Cell Open Research Endeavour (SCORE), WEHI
    affiliation_url: https://www.wehi.edu.au/people/shalin-naik/3310/score
date: "`r Sys.Date()`"
output: distill::distill_article
editor_options: 
  chunk_output_type: console
bibliography: ref.bib
---

```{r setup}
library(SingleCellExperiment)
library(here)
library(rmarkdown)
library(janitor)
library(BiocStyle)
library(ggplot2)
library(cowplot)
library(BiocParallel)

source(here("code", "helper_functions.R"))

# NOTE: Using >= 4 cores seizes up my laptop. Can use more on RStudio server.
options(
  "mc.cores" = 
    ifelse(Sys.info()[["nodename"]] == "rstudio-1.hpc.wehi.edu.au", 8L, 2L))
register(MulticoreParam(workers = getOption("mc.cores")))

knitr::opts_chunk$set(fig.path = "C057_Cooney.preprocess_files/")
```

# Setting up the data

We start from the demultiplexed *SingleCellExperiment* object created in ['Demultiplexing the Cooney (C057) memory CD4+ T-cell data set'](C057_Cooney.demultiplex.html).


```{r}
sce <- readRDS(here("data", "SCEs", "C057_Cooney.demultiplexed.SCE.rds"))
```

## Incorporating cell-based annotation

Cell-based annotations are included in the *colData* of the *SingleCellExperiment*.
We store the counts from the hashtag features as an 'alternative experiment'.

```{r}
colData(sce)[c("HTO", "Sample", "Treatment", "Replicate")] <- endoapply(
  colData(sce)[c("HTO", "Sample", "Treatment", "Replicate")], 
  function(x) {
    x[is.na(x)] <- "Unknown"
    factor(x)
  })
```

```{r}
hto_to_sample_df <- as.data.frame(
  colData(sce)[c("hto_cluster", "HTO", "Sample", "Treatment", "Replicate")]) %>%
  dplyr::distinct()

# Some useful colours
hto_cluster_colours <- sce$hto_cluster_colours[levels(sce$hto_cluster)]
hto_colours <- hto_cluster_colours
names(hto_colours) <- dplyr::inner_join(
  data.frame(hto_cluster = names(hto_cluster_colours)),
  hto_to_sample_df) %>%
  dplyr::pull(HTO)
sce$hto_colours <- hto_colours[sce$hto_cluster]
sample_colours <- hto_cluster_colours
names(sample_colours) <- dplyr::inner_join(
  data.frame(hto_cluster = names(sample_colours)),
  hto_to_sample_df) %>%
  dplyr::pull(Sample)
sce$sample_colours <- sample_colours[sce$Sample]
treatment_colours <- c(
  "Infected" = "#e41a1c",
  "Uninfected" = "#377eb8",
  "Unknown" = "grey70")
sce$treatment_colours <- treatment_colours[sce$Treatment]
# NOTE: No replicate_colours because we won't ever colour by this.
```

### Summary

This dataset contains samples from `r nlevels(sce$Sample)` samples.
All samples are human memory CD4+ T cells from 'humanised mice'.
Humanised mice are an immunodeficient strain and injected with human stem cells as pups which then differentiate into human hematopoietic cells as the mice mature.
Mice were infected or not infected with HTLV, with each condition done in biological triplicate (1 mouse / replicate).

```{r experiment-by-sample, fig.asp = 1/4, fig.cap = "Breakdown of the samples"}
ggplot(data.frame(Sample = sce$Sample)) + 
  geom_bar(aes(x = Sample, fill = Sample)) +
  coord_flip() +
  ylab("Number of droplets") +
  scale_fill_manual(values = sample_colours) +
  theme_cowplot(font_size = 6)
```

```{r experiment-by-treatment, fig.asp = 1/4, fig.cap = "Breakdown of the two treatments."}
plot_grid(
  ggplot(as.data.frame(colData(sce)[, c("Treatment", "Sample")])) + 
    geom_bar(
      aes(x = Treatment, fill = Sample),
      position = position_fill(reverse = TRUE)) +
    coord_flip() +
    ylab("Frequency") +
    scale_fill_manual(values = sample_colours) +
    theme_cowplot(font_size = 6),
  ggplot(as.data.frame(colData(sce)[, c("Treatment", "Sample")])) + 
    geom_bar(aes(x = Treatment, fill = Treatment)) +
    coord_flip() +
    ylab("Number of droplets") +
    scale_fill_manual(values = treatment_colours) +
    theme_cowplot(font_size = 6),
  align = "h",
  ncol = 2)
```

## Incorporating gene-based annotation

Having quantified gene expression against the Ensembl gene annotation, we have Ensembl-style identifiers for the genes. 
These identifiers are used as they are unambiguous and highly stable. 
However, they are difficult to interpret compared to the gene symbols which are more commonly used in the literature.
Given the Ensembl identifiers, we obtain the corresponding gene symbols using annotation packages available through Bioconductor.
Henceforth, we will use gene symbols (where available) to refer to genes in our analysis and otherwise use the Ensembl-style gene identifiers^[Some care is taken to account for missing and duplicate gene symbols; missing symbols are replaced with the Ensembl identifier and duplicated symbols are concatenated with the (unique) Ensembl identifiers.].

```{r}
library(scater)
rownames(sce) <- uniquifyFeatureNames(rowData(sce)$ID, rowData(sce)$Symbol)
# Add chromosome location so we can filter on mitochondrial genes.
library(AnnotationHub)
library(ensembldb)
ah <- AnnotationHub()
EnsDb.Hsapiens.v94 <- query(ah, c("EnsDb", "Homo Sapiens", 94))[[1]]
location <- mapIds(
  x = EnsDb.Hsapiens.v94, 
  # NOTE: Need to remove gene version number prior to lookup.
  keys = rowData(sce)$ID,
  keytype = "GENEID",
  column = "SEQNAME")
rowData(sce)$CHR <- location
```

```{r}
# Some useful gene sets
mito_set <- rownames(sce)[which(rowData(sce)$CHR == "MT")]
ribo_set <- grep("^RP(S|L)", rownames(sce), value = TRUE)
# NOTE: A more curated approach for identifying ribosomal protein genes 
#       (https://github.com/Bioconductor/OrchestratingSingleCellAnalysis-base/blob/ae201bf26e3e4fa82d9165d8abf4f4dc4b8e5a68/feature-selection.Rmd#L376-L380)
library(msigdbr)
c2_sets <- msigdbr(species = "Homo sapiens", category = "C2")
ribo_set <- union(
  ribo_set,
  c2_sets[c2_sets$gs_name == "KEGG_RIBOSOME", ]$human_gene_symbol)
```

# Quality control of cells

## Defining the quality control metrics

Low-quality cells need to be removed to ensure that technical effects do not distort downstream analysis results.
We use several quality control (QC) metrics to measure the quality of the cells:

- `sum`: This measures the library size of the cells, which is the total sum of counts across both genes and spike-in transcripts. We want cells to have high library sizes as this means more RNA has been successfully captured during library preparation. 
- `detected`: This is the number of expressed features^[The number of expressed features refers to the number of genes which have non-zero counts (i.e. they have been identified in the cell at least once)] in each cell. Cells with few expressed features are likely to be of poor quality, as the diverse transcript population has not been successful captured. 
- `subsets_Mt_percent`: This measures the proportion of reads which are mapped to mitochondrial RNA. If there is a higher than expected proportion of mitochondrial RNA this is often symptomatic of a cell which is under stress and is therefore of low quality and will not be used for the analysis. 

In summary, we aim to identify cells with low library sizes, few expressed genes, and very high percentages of spike-in transcripts (when available) or mitochondrial DNA.

```{r, results = "hide"}
is_mito <- rownames(sce) %in% mito_set
summary(is_mito)
sce <- addPerCellQC(sce, subsets = list(Mito = which(is_mito)))
```

## Visualizing the QC metrics

```{r qcplot-by-sample, fig.cap = "Distributions of various QC metrics for all cells in the dataset. This includes the library sizes, number of genes detected, and percentage of reads mapped to mitochondrial genes.", layout = "l-page", fig.asp = 0.5}
plot_grid(
  ggplot(
    data = as.data.frame(colData(sce)[, c("Sample", "Treatment", "sum")]),
    aes(x = Sample, y = sum, colour = Treatment, fill = Treatment)) +
    geom_violin(scale = "width", width = 0.8, alpha = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.01) +
    theme_cowplot(font_size = 4) +
    scale_colour_manual(values = treatment_colours) + 
    scale_fill_manual(values = treatment_colours) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_log10(limits = c(1, NA)) +
    annotation_logticks(
      sides = "l",
      short = unit(0.03, "cm"),
      mid = unit(0.06, "cm"),
      long = unit(0.09, "cm")),
  ggplot(
    data = as.data.frame(
      colData(sce)[, c("Sample", "Treatment", "subsets_Mito_percent")]),
    aes(
      x = Sample,
      y = subsets_Mito_percent,
      colour = Treatment,
      fill = Treatment)) +
    geom_violin(scale = "width", width = 0.8, alpha = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.01) +
    theme_cowplot(font_size = 4) +
    scale_colour_manual(values = treatment_colours) + 
    scale_fill_manual(values = treatment_colours) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    ylim(0, 100),
  ggplot(
    data = as.data.frame(colData(sce)[, c("Sample", "Treatment", "detected")]),
    aes(x = Sample, y = detected, colour = Treatment, fill = Treatment)) +
    geom_violin(scale = "width", width = 0.8, alpha = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.01) +
    theme_cowplot(font_size = 4) +
    scale_colour_manual(values = treatment_colours) + 
    scale_fill_manual(values = treatment_colours) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_log10(limits = c(1, NA)) +
    annotation_logticks(
      sides = "l",
      short = unit(0.03, "cm"),
      mid = unit(0.06, "cm"),
      long = unit(0.09, "cm")),
  ncol = 2,
  align = "v")
```

Figure \@ref(fig:qcplot-by-sample) shows that the vast majority of samples are good-quality; the library sizes are in the thousands^[This is consistent with the use of UMI counts rather than read counts, as each transcript molecule can only produce one UMI count but can yield many reads after fragmentation.], we observe around two thousand expressed genes per cell, and moderate mitochondrial percentages per cell.

It is notable that the `Unknown` samples have much smaller library sizes and fewer genes detected on average than the other samples.

It is also valuable to examine how the other QC metrics behave with respect to each other (Figure \@ref(fig:qcbiplot)). 
Generally, they will be in rough agreement, i.e., cells with low total counts will also have low numbers of expressed features and mitochondrial proportions.
Clear discrepancies may correspond to technical differences between batches of cells or genuine biological differences in RNA content.

```{r qcbiplot, fig.cap = "Behaviour of each QC metric compared to the total number of expressed features. Each point represents a cell in the data set.", fig.width = 10, fig.asp = 0.5}
par(mfrow = c(1, 2))
plot(
  x = sce$detected, 
  y = sce$sum/ 1e3,
  xlab = "Number of expressed genes",
  ylab = "Library size (thousands)")
plot(
  x = sce$sum, 
  y = sce$subsets_Mito_percent,
  xlab = "Library size",
  ylab = "Mitochondrial proportion (%)",
  log = "x")
```

For now, we retain the samples of `Unknown` origin because it may be interesting to see if these are from specific cell types.

## Identifying outliers by each metric

In calling cells from empty droplets, we have already removed cells with very low library sizes or (by association) low numbers of expressed genes.
Thus, further filtering on these metrics is not strictly necessary.

<aside>
See [`docs/C057_Cooney.demultiplex.html`](../docs/C057_Cooney.demultiplex.html) for removal of empty droplets.
</aside>

Filtering on the mitochondrial proportion provides the most additional benefit in this situation and so we seek to identify droplets with unusually large mitochondrial proportions (i.e. outliers).
Outlier thresholds are defined based on the median absolute deviation (MADs) from the median value of the metric across all cells. 
Here, we opt to use sample-specific thresholds to account for sample-specific differences^[It is important to note that we only using droplets assigned to a sample (i.e. we ignore `Unknown` samples) for the calculation of these thresholds.].

```{r}
sce$batch <- sce$Sample
mito_drop <- isOutlier(
  metric = sce$subsets_Mito_percent, 
  nmads = 3, 
  type = "higher",
  batch = sce$batch,
  subset = grepl("^human", sce$HTO))
mito_drop_df <- data.frame(
  sample = colnames(attributes(mito_drop)$thresholds),
  lower = attributes(mito_drop)$thresholds["higher", ])
```

The following table summarises the QC cutoffs:

```{r}
qc_cutoffs_df <- Reduce(
  function(x, y) dplyr::inner_join(x, y, by = "Sample"),
  list(mito_drop_df))
colnames(qc_cutoffs_df) <- c("batch", "%mito")
qc_cutoffs_df %>%
  dplyr::inner_join(
    dplyr::distinct(
      as.data.frame(colData(sce)[, c("batch"), drop = FALSE])),
    by = "batch") %>%
  dplyr::select(batch, dplyr::everything()) %>%
  dplyr::arrange(batch) %>%
  knitr::kable(caption = "Sample-specific QC metric cutoffs", digits = 1)
```

The vast majority of cells are retained for all samples.

```{r}
sce_pre_QC_outlier_removal <- sce
keep <- !mito_drop
sce_pre_QC_outlier_removal$keep <- keep
sce <- sce[, keep]
data.frame(
  ByMito = tapply(
    mito_drop, 
    sce_pre_QC_outlier_removal$batch, 
    sum,
    na.rm = TRUE),
  Remaining = as.vector(unname(table(sce$batch))),
  PercRemaining = round(
    100 * as.vector(unname(table(sce$batch))) /
      as.vector(
        unname(
          table(sce_pre_QC_outlier_removal$batch))), 1)) %>%
  tibble::rownames_to_column("batch") %>%
  dplyr::arrange(dplyr::desc(PercRemaining)) %>%
  knitr::kable(
    caption = "Number of samples removed by each QC step and the number of samples remaining.")
```

### Checking for removal of biologically relevant subpopulations

The biggest practical concern during QC is whether an entire cell type is inadvertently discarded.
There is always some risk of this occurring as the QC metrics are never fully independent of biological state.
We can diagnose cell type loss by looking for systematic differences in gene expression between the discarded and retained cells.

```{r}
lost <- calculateAverage(counts(sce_pre_QC_outlier_removal)[, !keep])
kept <- calculateAverage(counts(sce_pre_QC_outlier_removal)[, keep])

library(edgeR)
logged <- cpm(cbind(lost, kept), log = TRUE, prior.count = 2)
logFC <- logged[, 1] - logged[, 2]
abundance <- rowMeans(logged)
```

Figure \@ref(fig:qc-md-plot) shows the result of this analysis, highlighting that the systematically upregulated genes are mitochondrial transcripts and that those systematically downregulated genes are largely ribosomal protein genes.
This suggests that the QC step did not inadvertently filter out an entire biologically relevant subpopulation.

<aside>
An interactive version of Figure \@ref(fig:qc-md-plot) is available from [`output/glimma-plots/qc-md-plot.html`](../output/glimma-plots/qc-md-plot.html).
</aside>

```{r qc-md-plot, fig.cap = "Log-fold change in expression in the discarded cells compared to the retained cells. Each point represents a gene with mitochondrial transcripts in blue and ribosomal protein genes in orange. Dashed red lines indicate $|logFC| = 1", fig.asp = 0.7}
is_mito <- rownames(sce) %in% mito_set
is_ribo <- rownames(sce) %in% ribo_set

par(mfrow = c(1, 1))
plot(
  abundance,
  logFC,
  xlab = "Average count",
  ylab = "Log-FC (lost/kept)",
  pch = 16)
points(
  abundance[is_mito],
  logFC[is_mito],
  col = "dodgerblue",
  pch = 16,
  cex = 1)
points(
  abundance[is_ribo],
  logFC[is_ribo],
  col = "orange",
  pch = 16,
  cex = 1)
abline(h = c(-1, 1), col = "red", lty = 2)

library(Glimma)
glMDPlot(
  x = data.frame(abundance = abundance, logFC = logFC),
  xval = "abundance", 
  yval = "logFC",
  counts = cbind(lost, kept),
    anno = cbind(
      as.data.frame(rowData(sce_pre_QC_outlier_removal)), 
      data.frame(
        GeneID = rownames(sce_pre_QC_outlier_removal),
        stringsAsFactors = FALSE)),
  display.columns = c("Symbol", "ID", "CHR"),
  groups = factor(c("lost", "kept")),
  samples = c("lost", "kept"),
  status = unname(ifelse(is_mito, 1, ifelse(is_ribo, -1, 0))),
  transform = FALSE,
  main = "lost vs. kept",
  side.ylab = "Average count",
  cols = c("orange", "black", "dodgerBlue"),
  path = here("output"),
  html = "qc-md-plot",
  launch = FALSE)
```

If the discarded pool is enriched for a certain cell type, we should observe increased expression of the corresponding marker genes.

Another concern is whether the cells removed during QC preferentially derive from particular experimental groups.
Reassuringly, Figure \@ref(fig:barplot-highlighting-outliers) shows that this is not the case.

```{r barplot-highlighting-outliers, fig.cap = "Droplets removed during QC, stratified by `Sample`. "}
ggplot(
  as.data.frame(colData(sce_pre_QC_outlier_removal)[, c("Sample", "keep")])) + 
  geom_bar(aes(x = Sample, fill = keep)) + 
  ylab("Number of droplets") + 
  theme_cowplot(font_size = 9) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Finally, Figure \@ref(fig:qcplot-highlighting-outliers) compares the QC metrics of the discarded and retained droplets.

```{r qcplot-highlighting-outliers, fig.cap = "Distribution of QC metrics for each plate in the dataset. Each point represents a cell and is colored according to whether it was discarded during the QC process. Note that a cell will only be kept if it passes the relevant threshold for all four QC metrics.", layout = "l-page", fig.asp = 0.7}
plot_grid(
  ggplot(
    data = as.data.frame(
      colData(sce_pre_QC_outlier_removal)[, c("Sample", "sum", "keep")]),
    aes(x = Sample, y = sum)) +
    geom_violin(scale = "width", width = 0.8, alpha = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.01, aes(colour = keep)) +
    theme_cowplot(font_size = 4) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_log10(limits = c(1, NA)) +
    annotation_logticks(
      sides = "l",
      short = unit(0.03, "cm"),
      mid = unit(0.06, "cm"),
      long = unit(0.09, "cm")),
  ggplot(
    data = as.data.frame(
      colData(
        sce_pre_QC_outlier_removal)[, c(
          "Sample", "subsets_Mito_percent", "keep")]),
    aes(x = Sample, y = subsets_Mito_percent)) +
    geom_violin(scale = "width", width = 0.8, alpha = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.01, aes(colour = keep)) +
    theme_cowplot(font_size = 4) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    ylim(0, 100),
  ggplot(
    data = as.data.frame(
      colData(sce_pre_QC_outlier_removal)[, c("Sample", "detected", "keep")]),
    aes(x = Sample, y = detected)) +
    geom_violin(scale = "width", width = 0.8, alpha = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.01, aes(colour = keep)) +
    theme_cowplot(font_size = 4) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_log10(limits = c(1, NA)) +
    annotation_logticks(
      sides = "l",
      short = unit(0.03, "cm"),
      mid = unit(0.06, "cm"),
      long = unit(0.09, "cm")),
  ncol = 2,
  align = "v")
```

## Summary

We had already removed droplets that have unusually small library sizes or number of genes detected by the process of identifying empty droplets.
We have now further removed droplets whose mitochondrial proportions we deem to be an outlier.

For the time being, we opt to retain the `Unknown` droplets because these may allow us to identify a subpopulation of cells that are not captured by hashing.

<aside>
See [`docs/C057_Cooney.annotate.html`](../docs/C057_Cooney.annotate.html) for removal of `Unknown` droplets.
</aside>

To conclude, Figure \@ref(fig:qcplot-post-outlier-removal) shows that following QC that most samples have similar QC metrics, as is to be expected, and Figure \@ref(fig:experiment-by-sample-postqc) summarises the experimental design following QC.

```{r qcplot-post-outlier-removal, fig.cap = "Distributions of various QC metrics for all cells in the dataset passing QC. This includes the library sizes and proportion of reads mapped to mitochondrial genes.", layout = "l-body-outset", fig.asp = 0.7}
plot_grid(
  ggplot(
    data = as.data.frame(colData(sce)[, c("Sample", "Treatment", "sum")]),
    aes(x = Sample, y = sum, colour = Treatment, fill = Treatment)) +
    geom_violin(scale = "width", width = 0.8, alpha = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.01) +
    theme_cowplot(font_size = 4) +
    scale_colour_manual(values = treatment_colours) + 
    scale_fill_manual(values = treatment_colours) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_log10(limits = c(1, NA)) +
    annotation_logticks(
      sides = "l",
      short = unit(0.03, "cm"),
      mid = unit(0.06, "cm"),
      long = unit(0.09, "cm")),
  ggplot(
    data = as.data.frame(
      colData(sce)[, c("Sample", "Treatment", "subsets_Mito_percent")]),
    aes(
      x = Sample,
      y = subsets_Mito_percent,
      colour = Treatment,
      fill = Treatment)) +
    geom_violin(scale = "width", width = 0.8, alpha = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.01) +
    theme_cowplot(font_size = 4) +
    scale_colour_manual(values = treatment_colours) + 
    scale_fill_manual(values = treatment_colours) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    ylim(0, 100),
  ggplot(
    data = as.data.frame(colData(sce)[, c("Sample", "Treatment", "detected")]),
    aes(x = Sample, y = detected, colour = Treatment, fill = Treatment)) +
    geom_violin(scale = "width", width = 0.8, alpha = 0.2) +
    ggbeeswarm::geom_quasirandom(size = 0.01) +
    theme_cowplot(font_size = 4) +
    scale_colour_manual(values = treatment_colours) + 
    scale_fill_manual(values = treatment_colours) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_log10(limits = c(1, NA)) +
    annotation_logticks(
      sides = "l",
      short = unit(0.03, "cm"),
      mid = unit(0.06, "cm"),
      long = unit(0.09, "cm")),
  ncol = 2,
  align = "v")
```

```{r experiment-by-sample-postqc, fig.asp = 1 / 3, fig.cap = "Breakdown of the samples following QC."}
plot_grid(
  ggplot(as.data.frame(colData(sce)[, c("Treatment", "Sample")])) + 
    geom_bar(
      aes(x = Treatment, fill = Sample),
      position = position_fill(reverse = TRUE)) +
    coord_flip() +
    ylab("Frequency") +
    scale_fill_manual(values = sample_colours) +
    theme_cowplot(font_size = 6),
  ggplot(as.data.frame(colData(sce)[, c("Treatment", "Sample")])) + 
    geom_bar(aes(x = Treatment, fill = Treatment)) +
    coord_flip() +
    ylab("Number of droplets") +
    scale_fill_manual(values = treatment_colours) +
    theme_cowplot(font_size = 6),
  align = "h",
  ncol = 2)
```

# Examining gene-level metrics

## Inspecting the most highly expressed genes

Figure \@ref(fig:topgenes) shows the most highly expressed genes across the cell population in the combined data set.
Some of them are mitochondrial genes, matching what we've already seen in the QC metrics, and ribosomal protein genes, which commonly are amongst the most highly expressed genes in scRNA-seq data.

```{r topgenes, fig.asp = 1, fig.cap = "Percentage of total counts assigned to the top 50 most highly-abundant features in the combined data set. For each feature, each bar represents the percentage assigned to that feature for a single cell, while the circle represents the average across all cells."}
plotHighestExprs(sce, n = 50)
```

Figure \@ref(fig:topgenes-filtered) shows the most highly expressed endogenous genes after excluding the mitochondrial and ribosomal protein genes.

```{r topgenes-filtered, fig.asp = 1, fig.cap = "Percentage of total counts assigned to the top 50 most highly-abundant features in the combined data set. For each feature, each bar represents the percentage assigned to that feature for a single cell, while the circle represents the average across all cells. Bars are coloured by the total number of expressed features in each cell, while circles are coloured according to whether the feature is labelled as a control feature."}
plotHighestExprs(sce[!rownames(sce) %in% union(mito_set, ribo_set), ], n = 50)
```

## Filtering out low-abundance genes

Low-abundance genes are problematic as zero or near-zero counts do not contain much information for reliable statistical inference [@bourgon2010independent].
These genes typically do not provide enough evidence to reject the null hypothesis during testing, yet they still increase the severity of the multiple testing correction.
In addition, the discreteness of the counts may interfere with statistical procedures, e.g., by compromising the accuracy of continuous approximations.
Thus, low-abundance genes are often removed in many RNA-seq analysis pipelines before the application of downstream methods.

The 'optimal' choice of filtering strategy depends on the downstream application.
A more aggressive filter is usually required to remove discreteness (e.g., for normalization) compared to that required for removing underpowered tests.
For hypothesis testing, the filter statistic should also be independent of the test statistic under the null hypothesis.
Thus, we (or the relevant function) will filter at each step as needed, rather than applying a single filter for the entire analysis.

Several metrics can be used to define low-abundance genes.
The most obvious is the average count for each gene, computed across all cells in the data set.
We typically observe a peak of moderately expressed genes following a plateau of lowly expressed genes (Figure \@ref(fig:abhist)).

```{r abhist, fig.cap = "Histogram of log-average counts for all genes in the combined data set.", results = "hide"}
ave_counts <- calculateAverage(sce)
par(mfrow = c(1, 1))
hist(
  x = log10(ave_counts), 
  breaks = 100, 
  main = "", 
  col = "grey",
  xlab = expression(Log[10] ~ "average count"))
to_keep <- ave_counts > 0
sce <- sce[to_keep, ]
```

We remove `r sum(!to_keep)` genes that are not expressed in any cell.
Such genes provide no information and would be removed by any filtering strategy.
We retain `r sum(to_keep)` for downstream analysis.

# Normalization of cell-specific biases

Read counts are subject to differences in capture efficiency and sequencing depth between cells [@stegle2015computational].
Normalization is required to eliminate these cell-specific biases prior to downstream quantitative analyses.
This is often done by assuming that most genes are not differentially expressed (DE) between cells.
Any systematic difference in count size across the non-DE majority of genes between two cells is assumed to represent bias and is removed by scaling.
More specifically, 'size factors' are calculated that represent the extent to which counts should be scaled in each library.

## Using the deconvolution method to deal with zero counts

Size factors can be computed with several different approaches, e.g., using the `estimateSizeFactorsFromMatrix` function in the `r Biocpkg("DESeq2")` package [@anders2010differential;@love2014moderated], or with the `calcNormFactors` function [@robinson2010scaling] in the `r Biocpkg("edgeR")` package.
However, single-cell data can be problematic for these bulk data-based methods due to the dominance of low and zero counts.
To overcome this, we pool counts from many cells to increase the count size for accurate size factor estimation [@lun2016pooling].
Pool-based size factors are then 'deconvolved' into cell-based factors for cell-specific normalization.
This removes scaling biases associated with cell-specific differences in capture efficiency, sequencing depth and composition biases.

```{r, results = "hide"}
library(scran)
set.seed(943488)
clusters <- quickCluster(sce, BSPARAM = BiocSingular::IrlbaParam())
round(prop.table(table(clusters, sce$batch), 1), 2)
sce <- computeSumFactors(sce, clusters = clusters, min.mean = 0.1)
summary(sizeFactors(sce))
```

We check that the size factors are roughly aligned with the total library sizes (Figure \@ref(fig:normplot)).
Deviations from the diagonal correspond to composition biases due to differential expression between cell subpopulations.

```{r normplot, fig.cap = "Size factors from deconvolution, plotted against library sizes for all cells in each dataset. Axes are shown on a log-scale.", results = "hide", fig.asp = 1}
xlim <- c(0.1, max(sce$sum) / 1e3)
ylim <- range(sizeFactors(sce))

par(mfrow = c(3, 3))
lapply(levels(sce$Sample), function(s) {
  sce <- sce[, sce$Sample == s]
  plot(
    x = sce$sum / 1e3, 
    y = sizeFactors(sce), 
    log = "xy",
    xlab = "Library size (thousands)", 
    ylab = "Size factor",
    xlim = xlim,
    ylim = ylim,
    main = s,
    pch = 16,
    cex = 0.5)
})
```

## Applying the size factors to normalize gene expression

The count data are used to compute normalized log-expression values for use in downstream analyses.
Each value is defined as the log~2~-ratio of each count to the size factor for the corresponding cell, after adding a prior count of 1 to avoid undefined values at zero counts.
Division by the size factor ensures that any cell-specific biases are removed.

```{r, results = "hide"}
# NOTE: No need for multiBatchNorm() since the size factors were computed 
#       jointly using all samples.
sce <- logNormCounts(sce)
```

# Feature selection

## Motivation

We often use scRNA-seq data in exploratory analyses to characterize heterogeneity across cells.
Procedures like dimensionality reduction and clustering compare cells based on their gene expression profiles, which involves aggregating per-gene differences into a single (dis)similarity metric between a pair of cells.
The choice of genes to use in this calculation has a major impact on the behaviour of the metric and the performance of downstream methods.
We want to select genes that contain useful information about the biology of the system while removing genes that contain random noise.
This aims to preserve interesting biological structure without the variance that obscures that structure.
It also reduces the size of the dataset to improve computational efficiency of later steps.

## Quantifying per-gene variation

### Variance of the log-counts

The simplest approach to quantifying per-gene variation is to simply compute the variance of the log-normalized expression values (referred to as "log-counts" for simplicity) for each gene across all cells in the population [@lun2016step].
This has an advantage in that the feature selection is based on the same log-values that are used for later downstream steps.
In particular, genes with the largest variances in log-values will contribute the most to the Euclidean distances between cells.
By using log-values here, we ensure that our quantitative definition of heterogeneity is consistent throughout the entire analysis.

Calculation of the per-gene variance is simple but feature selection requires modelling of the mean-variance relationship.

### Quantifying technical noise

To account for the mean-variance relationship, we fit a trend to the variance with under the assumption of Poisson variation.
UMI counts typically exhibit near-Poisson variation if we only consider technical noise from library preparation and sequencing.

### Accounting for blocking factors

Data containing multiple batches will often exhibit batch effects.
We are usually not interested in highly variable genes (HVGs) that are driven by batch effects. 
Rather, we want to focus on genes that are highly variable within each batch.
This is naturally achieved by performing trend fitting and variance decomposition separately for each batch.

```{r}
var_fit <- modelGeneVarByPoisson(sce, block = sce$batch)
```

The use of a batch-specific trend fit is useful as it accommodates differences in the mean-variance trends between batches.
This is especially important if batches exhibit systematic technical differences, e.g., differences in coverage.

Figure \@ref(fig:trendplots) visualizes the quality of the batch-specific trend fits and highlights the need for batch-specific estimates of these fits.
The analysis of each batch yields estimates of the biological and technical components for each gene, which are averaged across batches.

```{r trendplots, fig.cap = "Variance in the data set as a function of the mean after blocking. Each plot represents the results for a single batch, each point represents a gene (black) and the blue line represents the Poisson trend.", fig.asp = 1, layout = "l-page"}
par(mfrow = c(3, 3))
blocked.stats <- var_fit$per.block
for (i in colnames(blocked.stats)) {
    current <- blocked.stats[[i]]
    plot(
      current$mean, 
      current$total, 
      main = i, 
      pch = 16, 
      cex = 0.5,
      xlab = "Mean of log-expression",
      ylab = "Variance of log-expression")
    curfit <- metadata(current)
    curve(curfit$trend(x), col = "dodgerblue", add = TRUE, lwd = 2) 
}
```

## Selecting highly variable genes (HVGs)

Once we have quantified the per-gene variation, the next step is to select the subset of HVGs to use in downstream analyses.
A larger subset will reduce the risk of discarding interesting biological signal by retaining more potentially relevant genes, at the cost of increasing noise from irrelevant genes that might obscure said signal.
It is difficult to determine the optimal trade-off for any given application as noise in one context may be useful signal in another.
For example, heterogeneity in T cell activation responses is an interesting phenomena but may be irrelevant noise in studies that only care about distinguishing the major immunophenotypes.

We opt to only remove the obviously uninteresting genes with variances below the trend.
By doing so, we avoid the need to make any judgement calls regarding what level of variation is interesting enough to retain.
This approach represents one extreme of the bias-variance trade-off where bias is minimized at the cost of maximizing noise.

```{r}
hvg <- getTopHVGs(var_fit, var.threshold = 0)
```

## Summary

We are left with `r length(hvg)` HVGs by this approach^[This is a large number of HVGs but the results don't qualitatively change by reducing this to, say, the top-1000 HVGs.].
Figure \@ref(fig:hvgs) shows the expression of the top-10 HVGs.

```{r hvgs, fig.cap = "Violin plots of normalized log-expression values for the top-10 HVGs. Each point represents the log-expression value in a single cell."}
plotExpression(object = sce, features = hvg[1:10])
```

# Dimensionality reduction

Many scRNA-seq analysis procedures involve comparing cells based on their expression values across multiple genes.
In these applications, each individual gene represents a dimension of the data. 
If we had a scRNA-seq data set with two genes, we could make a two-dimensional plot where each axis represents the expression of one gene and each point in the plot represents a cell.
Dimensionality reduction extends this idea to data sets with thousands of genes where each cellâ€™s expression profile defines its location in the high-dimensional expression space.

As the name suggests, dimensionality reduction aims to reduce the number of separate dimensions in the data.
This is possible because different genes are correlated if they are affected by the same biological process.
Thus, we do not need to store separate information for individual genes, but can instead compress multiple features into a single dimension.
This reduces computational work in downstream analyses, as calculations only need to be performed for a few dimensions rather than thousands of genes; reduces noise by averaging across multiple genes to obtain a more precise representation of the patterns in the data; and enables effective plotting of the data, for those of us who are not capable of visualizing more than 3 dimensions.

## Principal component analysis

Principal components analysis (PCA) discovers axes in high-dimensional space that capture the largest amount of variation.
In PCA, the first axis (or "principal component", PC) is chosen such that it captures the greatest variance across cells.
The next PC is chosen such that it is orthogonal to the first and captures the greatest remaining amount of variation, and so on.

By definition, the top PCs capture the dominant factors of heterogeneity in the data set.
Thus, we can perform dimensionality reduction by restricting downstream analyses to the top PCs.
This strategy is simple, highly effective and widely used throughout the data sciences.

When applying PCA to scRNA-seq data, our assumption is that biological processes affect multiple genes in a coordinated manner.
This means that the earlier PCs are likely to represent biological structure as more variation can be captured by considering the correlated behaviour of many genes.
By comparison, random technical or biological noise is expected to affect each gene independently.
There is unlikely to be an axis that can capture random variation across many genes, meaning that noise should mostly be concentrated in the later PCs.
This motivates the use of the earlier PCs in our downstream analyses, which concentrates the biological signal to simultaneously reduce computational work and remove noise.

We perform the PCA on the log-normalized expression values.
PCA is generally robust to random noise but an excess of it may cause the earlier PCs to capture noise instead of biological structure.
This effect can be avoided - or at least mitigated - by restricting the PCA to a subset of HVGs, as done in [Feature selection].

The choice of the number of PCs is a decision that is analogous to the choice of the number of HVGs to use.
Using more PCs will avoid discarding biological signal in later PCs, at the cost of retaining more noise.

We use the strategy of retaining all PCs until the percentage of total variation explained reaches some threshold.
We derive a suitable value for this threshold by calculating the proportion of variance in the data that is attributed to the biological component.
This is done using the the variance modelling results from [Quantifying per-gene variation].

```{r}
set.seed(67726)
sce <- denoisePCA(
  sce, 
  var_fit, 
  subset.row = hvg,
  BSPARAM = BiocSingular::IrlbaParam(deferred = TRUE))
```

This retains `r ncol(reducedDim(sce, "PCA"))` dimensions, which represents the lower bound on the number of PCs required to retain all biological variation.
Any fewer PCs will definitely discard some aspect of biological signal^[Note that the converse is not true, i.e., there is no guarantee that the retained PCs capture all of the signal, which is only generally possible if no dimensionality reduction is performed at all.].
This approach provides a reasonable choice when we want to retain as much signal as possible while still removing some noise.

## Dimensionality reduction for visualization

We use the uniform manifold approximation and projection (UMAP) method [@McInnes2018-hy] to perform further dimensionality reduction for visualization.

```{r}
library(uwot)
set.seed(853)
sce <- runUMAP(sce, dimred = "PCA")
umap_df <- cbind(
  data.frame(
    x = reducedDim(sce, "UMAP")[, 1],
    y = reducedDim(sce, "UMAP")[, 2]),
  as.data.frame(colData(sce)[, !colnames(colData(sce)) %in% c("TRA", "TRB")]))
```

Figure \@ref(fig:umap) visualizes the droplets using the UMAP co-ordinates.

```{r umap, fig.cap = "UMAP plot of the dataset. Each point represents a droplets and is coloured by `Sample`. Each panel highlights droplets from a particular sample.", fig.asp = 1}
bg <- dplyr::select(umap_df, -Sample)
ggplot(aes(x = x, y = y), data = umap_df) +
  geom_point(data = bg, colour = scales::alpha("grey", 0.5), size = 0.125) +
  geom_point(aes(colour = Sample), alpha = 1, size = 0.25) +
  scale_fill_manual(values = sample_colours, name = "HTO") +
  scale_colour_manual(values = sample_colours, name = "HTO") +
  theme_cowplot(font_size = 10) +
  xlab("Dimension 1") +
  ylab("Dimension 2") +
  facet_wrap(~ Sample, ncol = 3) +
  guides(colour = FALSE)
```

## Summary

Although Figure \@ref(fig:umap) is only a preliminary summary of the data, there are few points worth highlighting:

- In terms of UMAP co-ordinates, there are some visual differences between `Infected` and `Uninfected` samples that are consistent across replicates.
- The `Unknown` droplets are somewhat localised on the UMAP plot but these regions also contain droplets confidently assigned to a sample.

# Concluding remarks

```{r}
saveRDS(
  sce, 
  here("data", "SCEs", "C057_Cooney.preprocessed.SCE.rds"),
  compress = "xz")
```

The processed *SingleCellExperiment* object is available (see [`data/SCEs/C057_Cooney.preprocessed.SCE.rds`](../data/SCEs/C057_Cooney.preprocessed.SCE.rds)).
This will be used in downstream analyses, e.g., selecting biologically relevant cells.

# Additional information {.appendix}

The following are available on request:

- Full CSV tables of any data presented.
- PDF/PNG files of any static plots.

# Session info {.appendix}

<summary>The analysis and this document were prepared using the following software (click triangle to expand)</summary>
<details>

```{r}
sessioninfo::session_info()
```

</details>
